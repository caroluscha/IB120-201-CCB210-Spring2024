{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(boot)\n",
    "library(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You take a random sample of size n and calculate the sample mean. We use this sample mean as an *estimator* for the true population mean, also known as a \"point estimate\". A point estimate by itself is of limited usefulness because it does not reveal the uncertainty associated with the estimate or sampling method. Confidence intervals supply us with more information about the estimate by giving us an *interval*, with an associated *level of confidence*, that likely would contain the true population mean.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A confidence interval (CI) is an interval of values instead of a single point estimate.\n",
    "* The level of confidence corresponds to the expected proportion of intervals that will contain the parameter if many confidence intervals are constructed of the same sample size from the same population. Another way of saying this is: \n",
    "    * 90% of confidence intervals computed at the 90% confidence level contain the true parameter\n",
    "    * 95% of confidence intervals computed at the 95% confidence level contain the parameter\n",
    "    * etc...\n",
    "* Our uncertainty is about whether our particular CI is one of those that truly contains the true value of the parameter.\n",
    "* Constructing confidence intervals requires knowledge about the sample distribution - sample mean and either population SD or sample SD. \n",
    "* Calculating CIs, theoretically, does not require that the population follow a normal distribution, however the math for such situations can get tricky. For this reason, if we know the population doesn't follow a normal, or we're just unsure, we can instead calculate an asymptotical CI on the *sample distribution for the sample mean* (according to the Central Limit Theorem, the sampling distribution for the sample mean approaches normal).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General form:\n",
    "\n",
    "sample statistic $\\pm$ margin of error\n",
    "\n",
    "margin of error $=$ multiplier(standard error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Lab 8, we learned standard error $= \\frac{\\hat\\sigma}{\\sqrt n}$. The multiplier is calculated using t-statistics from a t-distribution. (There's a lot of theory behind this, but in short - this distribution applies when a test statistic we're interested in would follow a normal distribution *if* the value of a scaling term in the test statistic were known. When it's unknown, the scaling term is replaced by an estimate based on the data (the SEM).) Other statistical methods can be used to calculate the multiplier, but the t-distribution is widely used for when we don't know the true population standar deviation (which we rarely do). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example \n",
    "When the population follows a normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a random sample from the normal distribution\n",
    "n <- 50\n",
    "x <- rnorm(n, 0, 1) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of the sample\n",
    "hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample mean\n",
    "mean <- mean(x)\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question - Is there evidence that our true population mean is different from our sample mean?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard error of the mean\n",
    "sem <- sd(x)/sqrt(n)\n",
    "sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence interval with a confidence level of 95%\n",
    "ci <- c(mean-qt(0.975, n-1)*sem, mean+qt(0.975, n-1)*sem)\n",
    "ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret this? \n",
    "\n",
    "We are 95% confident that the true mean is within the above CI. Because the interval is centered around our sample mean, the answer to the above question is **no, there is no evidence that our true population mean is different from our sample mean**. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-sample t-test\n",
    "t.test(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned about one-sample t-tests in lecture, which determined whether our population mean was different from a particular value. We can also conduct two-sample t-tests to determine if there is a significant difference between the population means of two groups. Unlike the one-sample t-test, where the t-statistic is calculated using the difference between the sample mean and the value, divided by the standard error ($t = \\frac{difference}{standard error}$), the t-statistic for a two-sample t-test is $t = \\frac{difference of group averages}{standard error of difference}$. We then compare this t-statistic to a t-value, which depends on our chosen significance value and degrees of freedom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-sample t-test\n",
    "# draw a random sample from the normal distribution\n",
    "n <- 50\n",
    "y <- rnorm(n, 0, 1) \n",
    "print(mean(y))\n",
    "t.test(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "As mentioned, if the population doesn't follow a normal distribution, or we're unsure, we can construct a CI on the sampling distribution of the sample mean. However, collecting multiple samples, from which we can calculate sample means, is not always feasible. This is where bootstrapping comes in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How it works:\n",
    "\n",
    "Bootstrapping resamples the original dataset with replacement many thousands of times to create simulated datasets. This process involves drawing random samples from the original dataset. Breaking it down:\n",
    "\n",
    "* The bootstrap method has an equal probability of randomly drawing each original data point for inclusion in the resampled datasets.\n",
    "* The procedure can select a data point more than once for a resampled dataset. This property is the “with replacement” aspect of the process.\n",
    "* The procedure creates resampled datasets that are the same size as the original dataset.\n",
    "\n",
    "The process ends with your simulated datasets having many different combinations of the values that exist in the original dataset. Each simulated dataset has its own set of sample statistics, such as the mean. Bootstrapping procedures use the distribution of the sample statistics across the simulated samples as the sampling distribution.\n",
    "\n",
    "Keep in mind that bootstrapping does not create new data. Instead, it treats the original sample as a proxy for the real population and then draws random samples from it. Consequently, the central assumption for bootstrapping is that the original sample accurately represents the actual population. The resampling process creates many possible samples that a study could have drawn. The various combinations of values in the simulated samples collectively provide an estimate of the variability between random samples drawn from the same population. The range of these potential samples allows the procedure to construct confidence intervals and perform hypothesis testing. Importantly, as the sample size increases, bootstrapping converges on the correct sampling distribution under most conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example \n",
    "When the population doesn't follow a normal (or we're uncertain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual bootstrapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data for male cat body weight\n",
    "\n",
    "data <- data.frame(weight = c(catsM$Bwt))\n",
    "n <- length(data$weight)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of cat body weight \n",
    "hist(data$weight, breaks=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of cat body weight\n",
    "mean <- mean(data$weight)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 30 bootstrap samples and calculate their sample means\n",
    "bootReps <- 30\n",
    "means <- c()\n",
    "for(i in 1:bootReps){\n",
    "    sample <- sample(data$weight, size = n, replace = T)\n",
    "    means <- append(means, mean(sample))\n",
    "}\n",
    "hist(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the CI for the above sampling distribution of sample means\n",
    "meanOfMeans <- mean(means)\n",
    "semOfMeans <- sd(means)/sqrt(bootReps)\n",
    "ciOfMeans <- c(meanOfMeans-qt(0.975,bootReps-1)*semOfMeans, meanOfMeans+qt(0.975,bootReps-1)*semOfMeans)\n",
    "ciOfMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 100 bootstrap samples and calculate their sample means\n",
    "bootReps <- 100\n",
    "means <- c()\n",
    "for(i in 1:bootReps){\n",
    "    sample <- sample(data$weight, size = n, replace = T)\n",
    "    means <- append(means, mean(sample))\n",
    "}\n",
    "hist(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the CI for the above sampling distribution of sample means\n",
    "meanOfMeans <- mean(means)\n",
    "semOfMeans <- sd(means)/sqrt(bootReps)\n",
    "ciOfMeans <- c(meanOfMeans-qt(0.975,bootReps-1)*semOfMeans, meanOfMeans+qt(0.975,bootReps-1)*semOfMeans)\n",
    "ciOfMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 1000 bootstrap samples and calculate their sample means\n",
    "bootReps <- 1000\n",
    "means <- c()\n",
    "for(i in 1:bootReps){\n",
    "    sample <- sample(data$weight, size = n, replace = T)\n",
    "    means <- append(means, mean(sample))\n",
    "}\n",
    "hist(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the CI for the above sampling distribution of sample means\n",
    "meanOfMeans <- mean(means)\n",
    "semOfMeans <- sd(means)/sqrt(bootReps)\n",
    "ciOfMeans <- c(meanOfMeans-qt(0.975,bootReps-1)*semOfMeans, meanOfMeans+qt(0.975,bootReps-1)*semOfMeans)\n",
    "ciOfMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the sampling distribution in the histogram approximates a normal distribution even though the underlying data distribution is not. This approximation occurs thanks to the central limit theorem. As the sample size increases, the sampling distribution converges on a normal distribution regardless of the underlying data distribution (with a few exceptions).\n",
    "\n",
    "We can compare our original sample mean to the context of our simulated sample distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `boot()`:\n",
    "\n",
    "`boot()` calls the statistic function R times. Each time, it generates a set of random indices, with replacement, from the integers `1:nrow(data)`. These indices are used within the statistic function to select a sample. The statistics are calculated on the sample and the results are accumulated in the bootobject. \n",
    "\n",
    "**Note:** The function should include an indices parameter that the `boot()` function can use to select cases for each replication. Refer to example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the `statistic` function for the mean\n",
    "mean_fun <- function(data,index){\n",
    "  return(mean(data[index,]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a bootstrap analysis for 30 replicates\n",
    "res <- boot(data = data, R=30, statistic = mean_fun)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res$t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot.ci(res, conf = 0.95, type = \"norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a bootstrap analysis for 100 replicates\n",
    "res <- boot(data = data, R=100, statistic = mean_fun)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot.ci(res, conf = 0.95, type = \"norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a bootstrap analysis for 1000 replicates\n",
    "res <- boot(data = data, R=1000, statistic = mean_fun)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot.ci(res, conf = 0.95, type = \"norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean <- mean(res$t)\n",
    "sem <- sd(res$t)/sqrt(1000)\n",
    "ci <- c(mean - qt(0.975, 999)*sem, mean + qt(0.975, 999)*sem)\n",
    "ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question - Is there a statistically significant difference in weights between male and female cats?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there a statistically significant difference in weights between male and female cats?\n",
    "library(MASS)\n",
    "t.test(Bwt ~ Sex, data = cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the `iris` dataset, and find the mean and SEM of the `Sepal.Length`, `Sepal.Width`, `Petal.Length`, `Petal.Width`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate the variance of `Sepal.Length`, `Sepal.Width`, `Petal.Length`, `Petal.Width`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using the values calculated above, obtain the 95% confidence interval of the mean for `Sepal.Length`, `Sepal.Width`, `Petal.Length`, `Petal.Width`. What determines the range of the confidence interval? Report the confidence interval as a vector of the lower and upper bounds : `c(lower bound of CI, upper bound of CI)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using `boot()`, obtain 500 bootstrap samples out of `Sepal.Length`, `Sepal.Width`, `Petal.Length`, `Petal.Width`:\n",
    "\n",
    "    (a) Create a histogram of the bootstrap sample means\n",
    "\n",
    "    (b) Find the 95% bootstrap confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Perform a t-test between all combinations of the four datasets (that would be a total of 4 choose 2 = 6 combinations). See if there is any statistically significant difference (p < 0.05) between any of the four parameters defining the `iris`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
